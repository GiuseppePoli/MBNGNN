{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V_mqdC8yY2C",
        "outputId": "76f305d4-de33-4f94-d484-e6d9c161f613"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import scipy.io\n",
        "import h5py\n",
        "import sklearn\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import ttest_ind, mannwhitneyu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data, Dataset, InMemoryDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "import os\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from torch import Tensor\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import random\n",
        "from itertools import product\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MindDataset(InMemoryDataset):\n",
        "    def __init__(self, root, matrices_harm, strat_covars, adjacency_matrices, roi_data, transform=None, pre_transform=None):\n",
        "        self.matrices_harm = matrices_harm\n",
        "        self.strat_covars = strat_covars\n",
        "        self.adjacency_matrices = adjacency_matrices\n",
        "        self.roi_data = roi_data\n",
        "        super().__init__(root, transform, pre_transform)\n",
        "\n",
        "\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0], weights_only = False)\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return []\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['data.pt']\n",
        "\n",
        "    def process(self):\n",
        "        data_list = []\n",
        "\n",
        "        for i in range(len(self.matrices_harm)):\n",
        "            # Node features: all elements in a row\n",
        "            node_features = torch.tensor(self.matrices_harm[i], dtype=torch.float)\n",
        "            roi_features = torch.tensor(self.roi_data.iloc[i].values, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "            # gender = self.strat_covars['Gender'].iloc[i]\n",
        "            age = self.strat_covars['Age'].iloc[i]\n",
        "            age_gender_features = torch.tensor([[age]] * self.matrices_harm[i].shape[0], dtype=torch.float)\n",
        "            node_features = torch.cat([node_features, age_gender_features, roi_features], dim=1)\n",
        "\n",
        "            edge_index = torch.tensor(np.array(np.where(self.adjacency_matrices[i] == 1)), dtype=torch.long)\n",
        "\n",
        "            # edge_attr = []\n",
        "            # for j in range(edge_index.shape[1]):\n",
        "            #     edge_attr.append(torch.tensor(self.matrices_harm[i][edge_index[0, j], edge_index[1, j]], dtype=torch.float))\n",
        "            # edge_attr = torch.stack(edge_attr).unsqueeze(1)\n",
        "\n",
        "            data = Data(x=node_features, edge_index=edge_index, y=torch.tensor(self.strat_covars['Dx'].iloc[i], dtype=torch.long))\n",
        "            # data = Data(x=node_features, edge_index=edge_index, edge_attr = edge_attr, y=torch.tensor(self.strat_covars['Dx'].iloc[i], dtype=torch.long)) #WITH EDGE ATTRIBUTES\n",
        "\n",
        "            data_list.append(data)\n",
        "\n",
        "        data, slices = self.collate(data_list)\n",
        "        torch.save((data, slices), self.processed_paths[0])\n",
        "\n",
        "    def len(self):\n",
        "        return super().len()\n",
        "\n",
        "    def get(self, idx):\n",
        "        return super().get(idx)\n",
        "\n",
        "class NodeNorm(nn.Module):\n",
        "    def __init__(self, nn_type=\"n\", unbiased=False, eps=1e-5, power_root=2):\n",
        "        super(NodeNorm, self).__init__()\n",
        "        self.unbiased = unbiased\n",
        "        self.eps = eps\n",
        "        self.nn_type = nn_type\n",
        "        self.power = 1 / power_root\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.nn_type == \"n\":\n",
        "            mean = torch.mean(x, dim=1, keepdim=True)\n",
        "            std = (\n",
        "                torch.var(x, unbiased=self.unbiased, dim=1, keepdim=True) + self.eps\n",
        "            ).sqrt()\n",
        "            x = (x - mean) / std\n",
        "        elif self.nn_type == \"v\":\n",
        "            std = (\n",
        "                torch.var(x, unbiased=self.unbiased, dim=1, keepdim=True) + self.eps\n",
        "            ).sqrt()\n",
        "            x = x / std\n",
        "        elif self.nn_type == \"m\":\n",
        "            mean = torch.mean(x, dim=1, keepdim=True)\n",
        "            x = x - mean\n",
        "        elif self.nn_type == \"srv\":  # square root of variance\n",
        "            std = (\n",
        "                torch.var(x, unbiased=self.unbiased, dim=1, keepdim=True) + self.eps\n",
        "            ).sqrt()\n",
        "            x = x / torch.sqrt(std)\n",
        "        elif self.nn_type == \"pr\":\n",
        "            std = (\n",
        "                torch.var(x, unbiased=self.unbiased, dim=1, keepdim=True) + self.eps\n",
        "            ).sqrt()\n",
        "            x = x / torch.pow(std, self.power)\n",
        "        return x\n",
        "\n",
        "    def __repr__(self):\n",
        "        original_str = super().__repr__()\n",
        "        components = list(original_str)\n",
        "        nn_type_str = f\"nn_type={self.nn_type}\"\n",
        "        components.insert(-1, nn_type_str)\n",
        "        new_str = \"\".join(components)\n",
        "        return new_str\n",
        "\n",
        "def get_normalization(norm_type, num_channels=None):\n",
        "    if norm_type is None:\n",
        "        norm = None\n",
        "    elif norm_type == \"batch\":\n",
        "        norm = nn.BatchNorm1d(num_features=num_channels)\n",
        "    elif norm_type == \"node_n\":\n",
        "        norm = NodeNorm(nn_type=\"n\")\n",
        "    elif norm_type == \"node_v\":\n",
        "        norm = NodeNorm(nn_type=\"v\")\n",
        "    elif norm_type == \"node_m\":\n",
        "        norm = NodeNorm(nn_type=\"m\")\n",
        "    elif norm_type == \"node_srv\":\n",
        "        norm = NodeNorm(nn_type=\"srv\")\n",
        "    elif norm_type.find(\"node_pr\") != -1:\n",
        "        power_root = norm_type.split(\"_\")[-1]\n",
        "        power_root = int(power_root)\n",
        "        norm = NodeNorm(nn_type=\"pr\", power_root=power_root)\n",
        "    elif norm_type == \"layer\":\n",
        "        norm = nn.LayerNorm(normalized_shape=num_channels)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    return norm\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, norm_type=\"node_n\"):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.bns = torch.nn.ModuleList()\n",
        "\n",
        "        self.convs.append(GCNConv(input_dim, hidden_dim))\n",
        "        self.bns.append(get_normalization(norm_type=norm_type, num_channels=hidden_dim))\n",
        "        for _ in range(num_layers - 1):\n",
        "            self.convs.append(GCNConv(hidden_dim, hidden_dim))\n",
        "            self.bns.append(get_normalization(norm_type=norm_type, num_channels=hidden_dim))\n",
        "\n",
        "        self.fc = Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index, batch):\n",
        "\n",
        "        for conv, bn in zip(self.convs, self.bns):\n",
        "            x = F.relu(conv(x, edge_index))\n",
        "            x = bn(x)\n",
        "\n",
        "        x = global_mean_pool(x, batch)\n",
        "\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "import Confounder_Correction_Classes\n",
        "from Confounder_Correction_Classes import ComBatHarmonization\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    for data in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index, data.batch)\n",
        "        loss = F.cross_entropy(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        all_preds.append(out.argmax(dim=1).cpu().numpy())\n",
        "        all_labels.append(data.y.cpu().numpy())\n",
        "\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "    accuracy = (all_preds == all_labels).mean()\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "    train_loss = epoch_loss / len(train_loader)\n",
        "\n",
        "    return accuracy, train_loss, f1\n",
        "\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            out = model(data.x, data.edge_index, data.batch)\n",
        "            loss = F.cross_entropy(out, data.y)\n",
        "            total_loss += loss.item()\n",
        "            all_preds.append(out.argmax(dim=1).cpu().numpy())\n",
        "            all_labels.append(data.y.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "    accuracy = (all_preds == all_labels).mean()\n",
        "    f1 = f1_score(all_labels, all_preds, zero_division=1.0)\n",
        "    val_loss = total_loss / len(loader)\n",
        "\n",
        "    return accuracy, val_loss, f1, all_labels, all_preds\n",
        "\n",
        "def split_data(data, strat_covars, roi_data, indices_1, indices_2):\n",
        "\n",
        "    data_1 = data.drop(indices_2).reset_index(drop=True)\n",
        "    strat_covars_1 = strat_covars.drop(indices_2).reset_index(drop=True)\n",
        "    roi_1 = roi_data.drop(indices_2).reset_index(drop=True)\n",
        "\n",
        "    data_2 = data.drop(indices_1).reset_index(drop=True)\n",
        "    strat_covars_2 = strat_covars.drop(indices_1).reset_index(drop=True)\n",
        "    roi_2 = roi_data.drop(indices_1).reset_index(drop=True)\n",
        "\n",
        "    return data_1, strat_covars_1, roi_1, data_2, strat_covars_2, roi_2\n",
        "\n",
        "def reconstruct_and_create_adjacency(data_harm, threshold_percentile=90):\n",
        "    n_matrices, upper_triangle_size = data_harm.shape\n",
        "    N = int((1 + np.sqrt(1 + 8 * upper_triangle_size)) // 2)\n",
        "    matrices = np.zeros((n_matrices, N, N))\n",
        "    adjacency_matrices = np.zeros((n_matrices, N, N), dtype=int)\n",
        "\n",
        "    for i in range(n_matrices):\n",
        "        matrix = np.eye(N)\n",
        "        upper_indices = np.triu_indices(N, k=1)\n",
        "        matrix[upper_indices] = data_harm.iloc[i]\n",
        "        matrix = matrix + matrix.T\n",
        "        np.fill_diagonal(matrix, 1)\n",
        "        matrices[i] = matrix\n",
        "\n",
        "        threshold = np.percentile(matrix, threshold_percentile)\n",
        "        adjacency_matrices[i] = (matrix >= threshold).astype(int)\n",
        "\n",
        "    return matrices, adjacency_matrices\n",
        "\n",
        "def harmonize_data_2(data_1_raw, strat_covars_1, data_2_raw, strat_covars_2, ext_batch):\n",
        "    volumes_columns = np.arange(0, data_1_raw.shape[1])\n",
        "\n",
        "    feat_detail={'volumes':           {'id': volumes_columns,\n",
        "                                            'categorical': ['Gender'],\n",
        "                                            'continuous':['Age']}}\n",
        "\n",
        "    combat_function=ComBatHarmonization(cv_method=None, ref_batch=None,\n",
        "                                           regression_fit=0,\n",
        "                                           feat_detail=feat_detail,\n",
        "                                           feat_of_no_interest=None)\n",
        "\n",
        "    data_1_dict={'data': data_1_raw, 'covariates': strat_covars_1}\n",
        "    data_1_harm = combat_function.fit_transform(data_1_dict)\n",
        "    data_1_harm = pd.DataFrame(data_1_harm)\n",
        "\n",
        "    #Harmonize the test set\n",
        "    data_2_raw = pd.DataFrame(data_2_raw)\n",
        "    data_2_raw.columns = data_2_raw.columns.astype(int)\n",
        "    data_2_raw.index = pd.RangeIndex(start=0, stop=len(data_2_raw), step=1)\n",
        "    all_data = pd.concat([data_1_harm, data_2_raw], ignore_index=True)\n",
        "    all_strat_covars = pd.concat([strat_covars_1, strat_covars_2], ignore_index=True)\n",
        "    all_strat_covars.loc[all_strat_covars[\"batch\"] != ext_batch, \"batch\"] = 0\n",
        "\n",
        "\n",
        "    test_combat_function=ComBatHarmonization(cv_method=None, ref_batch=0,\n",
        "                                           regression_fit=0,\n",
        "                                           feat_detail=feat_detail,\n",
        "                                           feat_of_no_interest=None)\n",
        "\n",
        "    all_data_dict={'data': all_data, 'covariates': all_strat_covars}\n",
        "    all_data_harm = test_combat_function.fit_transform(all_data_dict)\n",
        "    all_data_harm = pd.DataFrame(all_data_harm)\n",
        "\n",
        "    data_2_harm = all_data_harm.drop(data_1_harm.index)\n",
        "    data_2_harm = data_2_harm.reset_index(drop=True)\n",
        "    data_2_harm = pd.DataFrame(data_2_harm)\n",
        "\n",
        "    return data_1_harm, data_2_harm\n",
        "\n",
        "def harmonize_data(train_data_raw, train_strat_covars, test_data_raw, test_strat_covars):\n",
        "\n",
        "            volumes_columns = np.arange(0, train_data_raw.shape[1])\n",
        "\n",
        "            feat_detail={'volumes':           {'id': volumes_columns,\n",
        "                                            'categorical': ['Gender'],\n",
        "                                            'continuous':['Age']}}\n",
        "\n",
        "            combat_function=ComBatHarmonization(cv_method=None, ref_batch=None,\n",
        "                                              regression_fit=0,\n",
        "                                              feat_detail=feat_detail,\n",
        "                                              feat_of_no_interest=None)\n",
        "\n",
        "            train_data_dict={'data': train_data_raw, 'covariates': train_strat_covars}\n",
        "            train_data_harm = combat_function.fit_transform(train_data_dict)\n",
        "            train_data_harm = pd.DataFrame(train_data_harm)\n",
        "\n",
        "            test_data_dict={'data': test_data_raw, 'covariates': test_strat_covars}\n",
        "            test_data_harm = combat_function.transform(test_data_dict)\n",
        "            test_data_harm = pd.DataFrame(test_data_harm)\n",
        "\n",
        "            return train_data_harm, test_data_harm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from torch import Tensor\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import random\n",
        "from itertools import product\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from torch_geometric.explain import Explainer, GNNExplainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNHZQM3H3k7f"
      },
      "source": [
        "# K-Fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jxM3xXT3kfw",
        "outputId": "d92ee3fa-eb89-401b-c117-894a9ade3c61"
      },
      "outputs": [],
      "source": [
        "ext_test_batches = [1, 3, 4, 5, 6, 7]\n",
        "indices_to_remove = [indices_to_remove_1, indices_to_remove_3, indices_to_remove_4, indices_to_remove_5, indices_to_remove_6, indices_to_remove_7] \n",
        "final_results = []\n",
        "all_node_feature_importances =[]\n",
        "all_feature_importances = []\n",
        "all_node_importances = []\n",
        "all_feature_importances_2 = []\n",
        "\n",
        "for ext_test_batch, indices in zip(ext_test_batches, indices_to_remove):\n",
        "    print(f\"Test batch: {ext_test_batch}\")\n",
        "\n",
        "    data_raw = pd.read_csv('data_raw_nmm_new.csv')\n",
        "    strat_covars = pd.read_csv('MatchedData01.csv')\n",
        "    roi_raw = pd.read_csv('roi_data_raw_nmm_norm.csv')\n",
        "\n",
        "    data_raw = data_raw.drop(indices)\n",
        "    strat_covars = strat_covars.drop(indices)\n",
        "    roi_raw = roi_raw.drop(indices)\n",
        "\n",
        "    #SEPARATE CROSS VALIDATION DATA AND EXTERNAL TEST SET DATA\n",
        "    ext_test_indices = strat_covars[strat_covars['batch'] == ext_test_batch].index\n",
        "    cv_indices = strat_covars[strat_covars[\"batch\"] != ext_test_batch].index\n",
        "\n",
        "    cv_data_raw, cv_strat_covars, cv_roi_raw, ext_test_data_raw, ext_test_strat_covars, ext_test_roi_raw = split_data(data_raw, strat_covars, roi_raw, cv_indices, ext_test_indices)\n",
        "\n",
        "    # Extract the best parameters\n",
        "    best_num_layers = best_num_layers_dict[ext_test_batch]\n",
        "    best_hidden_dim = best_hidden_dim_dict[ext_test_batch]\n",
        "    best_norm_type = best_norm_type_dict[ext_test_batch]\n",
        "    best_batch_size = best_batch_size_dict[ext_test_batch]\n",
        "\n",
        "    print(f\"Best parameters: num_layers={best_num_layers}, hidden_dim={best_hidden_dim}, norm_type={best_norm_type}, batch_size={best_batch_size}\")\n",
        "\n",
        "    cv_data_harm, ext_test_data_harm = harmonize_data_2(cv_data_raw, cv_strat_covars, ext_test_data_raw, ext_test_strat_covars, ext_test_batch)\n",
        "    cv_roi_harm, ext_test_roi_harm = harmonize_data_2(cv_roi_raw, cv_strat_covars, ext_test_roi_raw, ext_test_strat_covars, ext_test_batch)\n",
        "\n",
        "    ext_test_matrices_harm, ext_test_adjacency_matrices = reconstruct_and_create_adjacency(ext_test_data_harm)\n",
        "\n",
        "    ext_test_dataset_path = f\"Datasets/CV/MindDatasetExtTestNMM90_batch{ext_test_batch}\"\n",
        "    ext_test_dataset = MindDataset(\n",
        "        root=ext_test_dataset_path,\n",
        "        matrices_harm=ext_test_matrices_harm,\n",
        "        strat_covars=ext_test_strat_covars,\n",
        "        adjacency_matrices=ext_test_adjacency_matrices,\n",
        "        roi_data=ext_test_roi_harm\n",
        "    )\n",
        "\n",
        "    cv_matrices_harm, cv_adjacency_matrices = reconstruct_and_create_adjacency(cv_data_harm)\n",
        "    cv_dataset_path = f\"Datasets/CV/MindDatasetCVNMM90_batch{ext_test_batch}\"\n",
        "    cv_dataset = MindDataset(\n",
        "        root=cv_dataset_path,\n",
        "        matrices_harm=cv_matrices_harm,\n",
        "        strat_covars=cv_strat_covars,\n",
        "        adjacency_matrices=cv_adjacency_matrices,\n",
        "        roi_data=cv_roi_harm\n",
        "    )\n",
        "    train_indices, val_indices = train_test_split(range(len(cv_dataset)), test_size=0.3, random_state=3)\n",
        "    train_loader = DataLoader(cv_dataset[train_indices], batch_size=best_batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(cv_dataset[val_indices], batch_size=best_batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(ext_test_dataset, batch_size=best_batch_size, shuffle=False)\n",
        "\n",
        "    set_seed(42)\n",
        "\n",
        "    model = GCN(cv_dataset.num_features, hidden_dim=best_hidden_dim, output_dim=cv_dataset.num_classes, num_layers=best_num_layers, norm_type=best_norm_type)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    patience = 20\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_val_f1 = 0\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(100):\n",
        "\n",
        "        train_acc, train_loss, train_f1 = train()\n",
        "        val_acc, val_loss, val_f1, _, _ = evaluate(val_loader)  # Validation set metrics\n",
        "        print(\n",
        "            f\"Epoch: {epoch}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, Train F1: {train_f1:.4f}, \"\n",
        "            f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.4f}, Val F1: {val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), \"best_model_123.pt\")\n",
        "            print(f\"Saved best model at epoch {epoch} with Val Loss: {val_loss:.4f}\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch} as validation loss did not improve for {patience} consecutive epochs.\")\n",
        "            break\n",
        "\n",
        "\n",
        "    # Evaluate on test set after training is complete\n",
        "    model.load_state_dict(torch.load(\"best_model_123.pt\"))\n",
        "    test_acc, test_loss, test_f1, all_labels, all_preds = evaluate(test_loader)\n",
        "\n",
        "    test_prec = precision_score(all_labels, all_preds, zero_division=1.0)\n",
        "    test_recall = recall_score(all_labels, all_preds, zero_division=1.0)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
        "\n",
        "    final_results.append({\n",
        "                \"batch\": ext_test_batch,\n",
        "                \"num_layers\": best_num_layers,\n",
        "                \"hidden_dim\": best_hidden_dim,\n",
        "                \"norm_type\": best_norm_type,\n",
        "                \"batch_size\": best_batch_size,\n",
        "                \"accuracy\": test_acc*100,\n",
        "                \"loss\": test_loss,\n",
        "                \"f1\": test_f1*100,\n",
        "                \"precision\": test_prec*100,\n",
        "                \"recall\": test_recall*100,\n",
        "                \"true_negative\": tn,\n",
        "                \"false_positive\": fp,\n",
        "                \"false_negative\": fn,\n",
        "                \"true_positive\": tp\n",
        "            })\n",
        "\n",
        "    print(f\"External test {ext_test_batch} Accuracy: {test_acc:.4f}, Test F1: {test_f1:.4f}, Precision:{test_prec:.4f}, Recall:{test_recall:.4f}, True Negative {tn}, False Positive {fp}, False Negative {fn}, True Positive {tp}\")\n",
        "\n",
        "    ### NODE FEATURE IMPORTANCE ###\n",
        "\n",
        "    explainer = Explainer(\n",
        "    model=model,\n",
        "    algorithm=GNNExplainer(epochs=200),\n",
        "    explanation_type='model',\n",
        "    node_mask_type='attributes',\n",
        "    model_config=dict(\n",
        "        mode='binary_classification',\n",
        "        task_level='graph',\n",
        "        return_type='raw'),\n",
        "    )\n",
        "\n",
        "    explanations = []\n",
        "\n",
        "    for data in test_loader:\n",
        "        explanation = explainer(data.x, data.edge_index, batch = data.batch)\n",
        "        explanations.append(explanation)\n",
        "\n",
        "    all_node_masks = torch.cat([exp.node_mask for exp in explanations], dim=0)\n",
        "\n",
        "\n",
        "    num_features = all_node_masks.shape[1]\n",
        "    num_graphs = all_node_masks.shape[0] // 122\n",
        "\n",
        "    reshaped = all_node_masks.view(num_graphs, 122, num_features)\n",
        "\n",
        "    avg_node_feature_importance = reshaped.mean(dim=0)\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.heatmap(avg_node_feature_importance.numpy(), cmap=\"viridis\", xticklabels=10, yticklabels=10)\n",
        "    plt.xlabel(\"Feature\")\n",
        "    plt.ylabel(\"Node\")\n",
        "    plt.title(\"Average Node Feature Importance\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    node_ids, feature_ids = torch.meshgrid(\n",
        "        torch.arange(avg_node_feature_importance.size(0)),\n",
        "        torch.arange(avg_node_feature_importance.size(1)),\n",
        "        indexing='ij'\n",
        "    )\n",
        "\n",
        "    df_node_feature_importance = pd.DataFrame({\n",
        "        \"node\": node_ids.flatten().numpy(),\n",
        "        \"feature\": feature_ids.flatten().numpy(),\n",
        "        \"mean_importance\": avg_node_feature_importance.flatten().numpy()\n",
        "    })\n",
        "\n",
        "    df_node_feature_importance = df_node_feature_importance.sort_values(by=\"mean_importance\", ascending=False)\n",
        "\n",
        "    df_node_feature_importance.to_csv(f\"node_feature_importance_batch{ext_test_batch}.csv\", index=False)\n",
        "\n",
        "    all_node_feature_importances.append(df_node_feature_importance)\n",
        "\n",
        "    ### FEATURE IMPORTANCE ###\n",
        "\n",
        "    ### ALTERNATIVE METHOD ###\n",
        "    subject_feature_sums = reshaped.sum(dim=1)\n",
        "    feature_importance_2 = subject_feature_sums.mean(dim=0)\n",
        "    df_feature_importance_2 = pd.DataFrame({'Feature': range(len(feature_importance_2)), 'Importance': feature_importance_2})\n",
        "    df_feature_importance_2 = df_feature_importance_2.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    all_feature_importances_2.append(df_feature_importance_2.set_index('Feature'))\n",
        "\n",
        "    ######\n",
        "    feature_importance = all_node_masks.sum(dim=0)\n",
        "    df_feature_importance = pd.DataFrame({'Feature': range(len(feature_importance)), 'Importance': feature_importance})\n",
        "    df_feature_importance = df_feature_importance.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    #save df_feature_importance as a csv file\n",
        "    df_feature_importance.to_csv(f\"feature_importance_batch{ext_test_batch}.csv\", index=False)\n",
        "\n",
        "    all_feature_importances.append(df_feature_importance.set_index('Feature'))\n",
        "\n",
        "    feature_importance = feature_importance.numpy()\n",
        "\n",
        "    top_k = 20\n",
        "    sorted_idx = np.argsort(feature_importance)[::-1][:top_k]\n",
        "    top_features = feature_importance[sorted_idx]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(range(top_k), top_features[::-1], color='steelblue')\n",
        "    plt.yticks(range(top_k), [f'{i}' for i in sorted_idx[::-1]])\n",
        "    plt.xlabel(\"Importance Score\")\n",
        "    plt.title(f\"Top {top_k} Most Important Features\")\n",
        "\n",
        "    for i, val in enumerate(top_features[::-1]):\n",
        "        plt.text(val + 0.01, i, f'{val:.0f}', va='center', fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(df_feature_importance[df_feature_importance[\"Feature\"].isin([122, 123, 124])])\n",
        "\n",
        "    ### NODE IMPORTANCE ###\n",
        "\n",
        "    all_importance_scores = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "        for graph_idx in np.unique(data.batch.numpy()):\n",
        "            out, node_embeddings = model(data.x, data.edge_index, data.batch, return_embeddings=True)\n",
        "            predicted_class = out.argmax(dim=1)[graph_idx].item()  # Get class of selected graph\n",
        "            class_weights = model.fc.weight[predicted_class].detach().numpy()\n",
        "\n",
        "            mask = (data.batch.numpy() == graph_idx)  # Mask for nodes in the selected graph\n",
        "            importance_scores = node_embeddings[mask] @ torch.tensor(class_weights)\n",
        "            all_importance_scores.append(importance_scores.cpu().numpy())\n",
        "\n",
        "    all_importance_scores = np.vstack(all_importance_scores)\n",
        "    mean_importance_per_node = np.mean(all_importance_scores, axis=0)\n",
        "\n",
        "    df_node_importance = pd.DataFrame({'Feature': range(len(mean_importance_per_node)), 'Importance': mean_importance_per_node})\n",
        "\n",
        "    df_node_importance.to_csv(f\"node_importance_batch{ext_test_batch}.csv\", index=False)\n",
        "\n",
        "    all_node_importances.append(df_node_importance.set_index('Feature'))\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.heatmap(mean_importance_per_node.reshape(-1, 1), cmap=\"Reds\")\n",
        "    plt.title(\"Node Importance via CAM\")\n",
        "    plt.xlabel(\"Importance Score\")\n",
        "    plt.ylabel(\"Nodes\")\n",
        "    plt.show()\n",
        "\n",
        "all_dfs_concat = pd.concat(all_node_feature_importances)\n",
        "avg_node_feature_df = all_dfs_concat.groupby(['node', 'feature'], as_index=False)['mean_importance'].mean()\n",
        "avg_node_feature_df.to_csv(\"avg_node_feature_df.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Importance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "nmm = pd.read_csv(\"neuromorphometrics_original.csv\", sep = \";\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "ROIid",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "ROIname",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Vgm",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Vwm",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Vcsf",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "ROIcolor",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "CircNumber",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "CircRegion",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "CircLabel",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Hemisphere",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "ref": "2adf9d44-6e34-4c37-aa0a-a763ec01d9ca",
              "rows": [
                [
                  "0",
                  "23",
                  "Right Accumbens Area",
                  "1",
                  "0",
                  "0",
                  "102 102 255",
                  "116",
                  "Basal ganglia",
                  "Accumbens",
                  "right"
                ],
                [
                  "1",
                  "30",
                  "Left Accumbens Area",
                  "1",
                  "0",
                  "0",
                  "102 102 255",
                  "52",
                  "Basal ganglia",
                  "Accumbens",
                  "left"
                ],
                [
                  "2",
                  "31",
                  "Right Amygdala",
                  "1",
                  "0",
                  "0",
                  "255 177 100",
                  "114",
                  "Amygdala",
                  "Amygdala",
                  "right"
                ],
                [
                  "3",
                  "32",
                  "Left Amygdala",
                  "1",
                  "0",
                  "0",
                  "255 177 100",
                  "50",
                  "Amygdala",
                  "Amygdala",
                  "left"
                ],
                [
                  "4",
                  "36",
                  "Right Caudate",
                  "1",
                  "0",
                  "0",
                  "255 0 255",
                  "117",
                  "Basal ganglia",
                  "Caudate",
                  "right"
                ],
                [
                  "5",
                  "37",
                  "Left Caudate",
                  "1",
                  "0",
                  "0",
                  "255 0 255",
                  "53",
                  "Basal ganglia",
                  "Caudate",
                  "left"
                ],
                [
                  "6",
                  "38",
                  "Right Cerebellum Exterior",
                  "1",
                  "0",
                  "0",
                  "102 0 0",
                  "126",
                  "Cerebellum",
                  "exterior",
                  "right"
                ],
                [
                  "7",
                  "39",
                  "Left Cerebellum Exterior",
                  "1",
                  "0",
                  "0",
                  "102 0 0",
                  "62",
                  "Cerebellum",
                  "exterior",
                  "left"
                ],
                [
                  "8",
                  "47",
                  "Right Hippocampus",
                  "1",
                  "0",
                  "0",
                  "255 0 0",
                  "122",
                  "Hippocampus",
                  "Hippocampus",
                  "right"
                ],
                [
                  "9",
                  "48",
                  "Left Hippocampus",
                  "1",
                  "0",
                  "0",
                  "255 0 0",
                  "58",
                  "Hippocampus",
                  "Hippocampus",
                  "left"
                ],
                [
                  "10",
                  "55",
                  "Right Pallidum",
                  "1",
                  "0",
                  "0",
                  "0 255 255",
                  "118",
                  "Basal ganglia",
                  "Pallidum",
                  "right"
                ],
                [
                  "11",
                  "56",
                  "Left Pallidum",
                  "1",
                  "0",
                  "0",
                  "0 255 255",
                  "54",
                  "Basal ganglia",
                  "Pallidum",
                  "left"
                ],
                [
                  "12",
                  "57",
                  "Right Putamen",
                  "1",
                  "0",
                  "0",
                  "255 0 255",
                  "119",
                  "Basal ganglia",
                  "Putamen",
                  "right"
                ],
                [
                  "13",
                  "58",
                  "Left Putamen",
                  "1",
                  "0",
                  "0",
                  "255 0 255",
                  "55",
                  "Basal ganglia",
                  "Putamen",
                  "left"
                ],
                [
                  "14",
                  "59",
                  "Right Thalamus Proper",
                  "1",
                  "0",
                  "0",
                  "102 0 0",
                  "120",
                  "Basal ganglia",
                  "Thalamus",
                  "right"
                ],
                [
                  "15",
                  "60",
                  "Left Thalamus Proper",
                  "1",
                  "0",
                  "0",
                  "102 0 0",
                  "56",
                  "Basal ganglia",
                  "Thalamus",
                  "left"
                ],
                [
                  "16",
                  "61",
                  "Right Ventral DC",
                  "1",
                  "1",
                  "0",
                  "0 102 0",
                  "121",
                  "Diencephalon",
                  "ventral",
                  "right"
                ],
                [
                  "17",
                  "62",
                  "Left Ventral DC",
                  "1",
                  "1",
                  "0",
                  "0 102 0",
                  "57",
                  "Diencephalon",
                  "ventral",
                  "left"
                ],
                [
                  "18",
                  "69",
                  "Optic Chiasm",
                  "1",
                  "0",
                  "0",
                  "0 204 0",
                  "133",
                  "Optic chaism",
                  "Optic chaism",
                  "both"
                ],
                [
                  "19",
                  "71",
                  "Cerebellar Vermal Lobules I-V",
                  "1",
                  "1",
                  "0",
                  "255 0 0",
                  "129",
                  "Cerebellum",
                  "Cerebellum",
                  "both"
                ],
                [
                  "20",
                  "72",
                  "Cerebellar Vermal Lobules VI-VII",
                  "1",
                  "1",
                  "0",
                  "102 102 255",
                  "130",
                  "Cerebellum",
                  "Cerebellum",
                  "both"
                ],
                [
                  "21",
                  "73",
                  "Cerebellar Vermal Lobules VIII-X",
                  "1",
                  "1",
                  "0",
                  "255 177 100",
                  "131",
                  "Cerebellum",
                  "Cerebellum",
                  "both"
                ],
                [
                  "22",
                  "75",
                  "Left Basal Forebrain",
                  "1",
                  "0",
                  "0",
                  "255 177 100",
                  "115",
                  "Basal Forebrain",
                  "Basal Forebrain",
                  "right"
                ],
                [
                  "23",
                  "76",
                  "Right Basal Forebrain",
                  "1",
                  "0",
                  "0",
                  "0 255 255",
                  "51",
                  "Basal Forebrain",
                  "Basal Forebrain",
                  "left"
                ],
                [
                  "24",
                  "100",
                  "Right ACgG anterior cingulate gyrus",
                  "1",
                  "0",
                  "0",
                  "255 0 255",
                  "109",
                  "Limbic cortex",
                  "cingulate",
                  "right"
                ],
                [
                  "25",
                  "101",
                  "Left ACgG anterior cingulate gyrus",
                  "1",
                  "0",
                  "0",
                  "255 0 255",
                  "45",
                  "Limbic cortex",
                  "cingulate",
                  "left"
                ],
                [
                  "26",
                  "102",
                  "Right AIns anterior insula",
                  "1",
                  "0",
                  "0",
                  "102 0 0",
                  "69",
                  "Frontal lobe",
                  "insular",
                  "right"
                ],
                [
                  "27",
                  "103",
                  "Left AIns anterior insula",
                  "1",
                  "0",
                  "0",
                  "102 0 0",
                  "5",
                  "Frontal lobe",
                  "insular",
                  "left"
                ],
                [
                  "28",
                  "104",
                  "Right AOrG anterior orbital gyrus",
                  "1",
                  "0",
                  "0",
                  "0 102 0",
                  "65",
                  "Frontal lobe",
                  "inferior",
                  "right"
                ],
                [
                  "29",
                  "105",
                  "Left AOrG anterior orbital gyrus",
                  "1",
                  "0",
                  "0",
                  "0 102 0",
                  "1",
                  "Frontal lobe",
                  "inferior",
                  "left"
                ],
                [
                  "30",
                  "106",
                  "Right AnG angular gyrus",
                  "1",
                  "0",
                  "0",
                  "255 215 0",
                  "103",
                  "Parietal lobe",
                  "lateral",
                  "right"
                ],
                [
                  "31",
                  "107",
                  "Left AnG angular gyrus",
                  "1",
                  "0",
                  "0",
                  "255 215 0",
                  "39",
                  "Parietal lobe",
                  "lateral",
                  "left"
                ],
                [
                  "32",
                  "108",
                  "Right Calc calcarine cortex",
                  "1",
                  "0",
                  "0",
                  "0 204 0",
                  "100",
                  "Occipital lobe",
                  "medial",
                  "right"
                ],
                [
                  "33",
                  "109",
                  "Left Calc calcarine cortex",
                  "1",
                  "0",
                  "0",
                  "0 204 0",
                  "36",
                  "Occipital lobe",
                  "medial",
                  "left"
                ],
                [
                  "34",
                  "112",
                  "Right CO central operculum",
                  "1",
                  "0",
                  "0",
                  "255 0 0",
                  "84",
                  "Frontal lobe",
                  "opercular",
                  "right"
                ],
                [
                  "35",
                  "113",
                  "Left CO central operculum",
                  "1",
                  "0",
                  "0",
                  "255 0 0",
                  "20",
                  "Frontal lobe",
                  "opercular",
                  "left"
                ],
                [
                  "36",
                  "114",
                  "Right Cun cuneus",
                  "1",
                  "0",
                  "0",
                  "102 102 255",
                  "101",
                  "Occipital lobe",
                  "medial",
                  "right"
                ],
                [
                  "37",
                  "115",
                  "Left Cun cuneus",
                  "1",
                  "0",
                  "0",
                  "102 102 255",
                  "37",
                  "Occipital lobe",
                  "medial",
                  "left"
                ],
                [
                  "38",
                  "116",
                  "Right Ent entorhinal area",
                  "1",
                  "0",
                  "0",
                  "255 177 100",
                  "112",
                  "Limbic cortex",
                  "medial-temporal",
                  "right"
                ],
                [
                  "39",
                  "117",
                  "Left Ent entorhinal area",
                  "1",
                  "0",
                  "0",
                  "255 177 100",
                  "48",
                  "Limbic cortex",
                  "medial-temporal",
                  "left"
                ],
                [
                  "40",
                  "118",
                  "Right FO frontal operculum",
                  "1",
                  "0",
                  "0",
                  "0 255 255",
                  "85",
                  "Frontal lobe",
                  "opercular",
                  "right"
                ],
                [
                  "41",
                  "119",
                  "Left FO frontal operculum",
                  "1",
                  "0",
                  "0",
                  "0 255 255",
                  "21",
                  "Frontal lobe",
                  "opercular",
                  "left"
                ],
                [
                  "42",
                  "120",
                  "Right FRP frontal pole",
                  "1",
                  "0",
                  "0",
                  "255 0 255",
                  "71",
                  "Frontal lobe",
                  "lateral",
                  "right"
                ],
                [
                  "43",
                  "121",
                  "Left FRP frontal pole",
                  "1",
                  "0",
                  "0",
                  "255 0 255",
                  "7",
                  "Frontal lobe",
                  "lateral",
                  "left"
                ],
                [
                  "44",
                  "122",
                  "Right FuG fusiform gyrus",
                  "1",
                  "0",
                  "0",
                  "102 0 0",
                  "87",
                  "Temporal lobe",
                  "inferior",
                  "right"
                ],
                [
                  "45",
                  "123",
                  "Left FuG fusiform gyrus",
                  "1",
                  "0",
                  "0",
                  "102 0 0",
                  "23",
                  "Temporal lobe",
                  "inferior",
                  "left"
                ],
                [
                  "46",
                  "124",
                  "Right GRe gyrus rectus",
                  "1",
                  "0",
                  "0",
                  "0 102 0",
                  "78",
                  "Frontal lobe",
                  "medial",
                  "right"
                ],
                [
                  "47",
                  "125",
                  "Left GRe gyrus rectus",
                  "1",
                  "0",
                  "0",
                  "0 102 0",
                  "14",
                  "Frontal lobe",
                  "medial",
                  "left"
                ],
                [
                  "48",
                  "128",
                  "Right IOG inferior occipital gyrus",
                  "1",
                  "0",
                  "0",
                  "255 215 0",
                  "96",
                  "Occipital lobe",
                  "lateral",
                  "right"
                ],
                [
                  "49",
                  "129",
                  "Left IOG inferior occipital gyrus",
                  "1",
                  "0",
                  "0",
                  "255 215 0",
                  "32",
                  "Occipital lobe",
                  "lateral",
                  "left"
                ]
              ],
              "shape": {
                "columns": 10,
                "rows": 122
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ROIid</th>\n",
              "      <th>ROIname</th>\n",
              "      <th>Vgm</th>\n",
              "      <th>Vwm</th>\n",
              "      <th>Vcsf</th>\n",
              "      <th>ROIcolor</th>\n",
              "      <th>CircNumber</th>\n",
              "      <th>CircRegion</th>\n",
              "      <th>CircLabel</th>\n",
              "      <th>Hemisphere</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23</td>\n",
              "      <td>Right Accumbens Area</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>102 102 255</td>\n",
              "      <td>116</td>\n",
              "      <td>Basal ganglia</td>\n",
              "      <td>Accumbens</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30</td>\n",
              "      <td>Left Accumbens Area</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>102 102 255</td>\n",
              "      <td>52</td>\n",
              "      <td>Basal ganglia</td>\n",
              "      <td>Accumbens</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31</td>\n",
              "      <td>Right Amygdala</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255 177 100</td>\n",
              "      <td>114</td>\n",
              "      <td>Amygdala</td>\n",
              "      <td>Amygdala</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>32</td>\n",
              "      <td>Left Amygdala</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255 177 100</td>\n",
              "      <td>50</td>\n",
              "      <td>Amygdala</td>\n",
              "      <td>Amygdala</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36</td>\n",
              "      <td>Right Caudate</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255 0 255</td>\n",
              "      <td>117</td>\n",
              "      <td>Basal ganglia</td>\n",
              "      <td>Caudate</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>203</td>\n",
              "      <td>Left TMP temporal pole</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>102 0 0</td>\n",
              "      <td>27</td>\n",
              "      <td>Temporal lobe</td>\n",
              "      <td>lateral</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>204</td>\n",
              "      <td>Right TrIFG triangular part of the inferior fr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0 102 0</td>\n",
              "      <td>77</td>\n",
              "      <td>Frontal lobe</td>\n",
              "      <td>lateral</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>205</td>\n",
              "      <td>Left TrIFG triangular part of the inferior fro...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0 102 0</td>\n",
              "      <td>13</td>\n",
              "      <td>Frontal lobe</td>\n",
              "      <td>lateral</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>206</td>\n",
              "      <td>Right TTG transverse temporal gyrus</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255 215 0</td>\n",
              "      <td>94</td>\n",
              "      <td>Temporal lobe</td>\n",
              "      <td>supra-temporal</td>\n",
              "      <td>right</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>207</td>\n",
              "      <td>Left TTG transverse temporal gyrus</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>255 215 0</td>\n",
              "      <td>30</td>\n",
              "      <td>Temporal lobe</td>\n",
              "      <td>supra-temporal</td>\n",
              "      <td>left</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>122 rows  10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     ROIid                                            ROIname  Vgm  Vwm  Vcsf  \\\n",
              "0       23                               Right Accumbens Area    1    0     0   \n",
              "1       30                                Left Accumbens Area    1    0     0   \n",
              "2       31                                     Right Amygdala    1    0     0   \n",
              "3       32                                      Left Amygdala    1    0     0   \n",
              "4       36                                      Right Caudate    1    0     0   \n",
              "..     ...                                                ...  ...  ...   ...   \n",
              "117    203                             Left TMP temporal pole    1    0     0   \n",
              "118    204  Right TrIFG triangular part of the inferior fr...    1    0     0   \n",
              "119    205  Left TrIFG triangular part of the inferior fro...    1    0     0   \n",
              "120    206                Right TTG transverse temporal gyrus    1    0     0   \n",
              "121    207                 Left TTG transverse temporal gyrus    1    0     0   \n",
              "\n",
              "        ROIcolor  CircNumber     CircRegion       CircLabel Hemisphere  \n",
              "0    102 102 255         116  Basal ganglia       Accumbens      right  \n",
              "1    102 102 255          52  Basal ganglia       Accumbens       left  \n",
              "2    255 177 100         114       Amygdala        Amygdala      right  \n",
              "3    255 177 100          50       Amygdala        Amygdala       left  \n",
              "4      255 0 255         117  Basal ganglia         Caudate      right  \n",
              "..           ...         ...            ...             ...        ...  \n",
              "117      102 0 0          27  Temporal lobe         lateral       left  \n",
              "118      0 102 0          77   Frontal lobe         lateral      right  \n",
              "119      0 102 0          13   Frontal lobe         lateral       left  \n",
              "120    255 215 0          94  Temporal lobe  supra-temporal      right  \n",
              "121    255 215 0          30  Temporal lobe  supra-temporal       left  \n",
              "\n",
              "[122 rows x 10 columns]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nmm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "node_names = nmm['ROIname'].tolist()         \n",
        "circ_regions = nmm['CircRegion'].tolist()   \n",
        "extra_features = ['Age', 'ROI Volume']\n",
        "extra_regions = ['None'] * 2\n",
        "\n",
        "feature_names =node_names + extra_features\n",
        "all_circ_regions = circ_regions + extra_regions\n",
        "\n",
        "node_name_map = {i: name for i, name in enumerate(node_names)}\n",
        "feature_name_map = {i: name for i, name in enumerate(feature_names)}\n",
        "circ_region_map = {i: region for i, region in enumerate(all_circ_regions)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Node Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_node_feature_df = pd.read_csv(\"avg_node_feature_df.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_node_feature_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_matrix_df = avg_node_feature_df.pivot(index='node', columns='feature', values='mean_importance')\n",
        "\n",
        "avg_matrix = avg_matrix_df.values\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(avg_matrix, cmap=\"viridis\", xticklabels=10, yticklabels=10)\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.ylabel(\"Node\")\n",
        "# plt.title(\"Average Node Feature Importance\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"node_feature_importance.png\", dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_node_feature_df['node_name'] = avg_node_feature_df['node'].map(node_name_map)\n",
        "avg_node_feature_df['feature_name'] = avg_node_feature_df['feature'].map(feature_name_map)\n",
        "avg_node_feature_df['CircNode'] = avg_node_feature_df['node'].map(circ_region_map)\n",
        "avg_node_feature_df['CircFeature'] = avg_node_feature_df['feature'].map(circ_region_map)\n",
        "avg_node_feature_df = avg_node_feature_df.sort_values(by=\"mean_importance\", ascending=False).reset_index(drop=True)\n",
        "avg_node_feature_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mean_per_feature = avg_matrix_df.mean(axis=0).sort_values(ascending=False)*100\n",
        "\n",
        "# Create final DataFrame\n",
        "df_mean_importance = mean_per_feature.reset_index()\n",
        "df_mean_importance.columns = ['Feature', 'AverageImportance']\n",
        "\n",
        "# Sort descending by importance\n",
        "df_mean_importance = df_mean_importance.sort_values(by='AverageImportance', ascending=False)\n",
        "df_mean_importance.reset_index(drop=True, inplace=True)\n",
        "df_mean_importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_mean_importance['FeatureName'] = df_mean_importance['Feature'].map(feature_name_map)\n",
        "df_mean_importance['CircRegion'] = df_mean_importance['Feature'].map(circ_region_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_mean_importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Apply a clean style\n",
        "sns.set_theme(style=\"ticks\")\n",
        "\n",
        "# Number of top features\n",
        "top_k = 20\n",
        "\n",
        "# Get top k sorted rows by importance\n",
        "top_df = df_mean_importance.nlargest(top_k, 'AverageImportance').copy()\n",
        "top_df = top_df[::-1]  # Reverse for barh plotting\n",
        "\n",
        "# Define colors by CircRegion using a color palette\n",
        "unique_regions = top_df['CircRegion'].unique()\n",
        "palette = sns.color_palette(\"deep\", len(unique_regions))[::-1]\n",
        "region_color_map = {region: palette[i] for i, region in enumerate(unique_regions)}\n",
        "bar_colors = top_df['CircRegion'].map(region_color_map)\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.barh(range(top_k), top_df['AverageImportance'], color=bar_colors)\n",
        "\n",
        "sns.despine()\n",
        "\n",
        "# Y-axis feature labels\n",
        "plt.yticks(range(top_k), top_df['FeatureName'], fontsize=10)\n",
        "\n",
        "# Add text annotations (importance scores)\n",
        "for i, val in enumerate(top_df['AverageImportance']):\n",
        "    plt.text(val + 0.01, i, f'{val:.2f}', va='center', fontsize=9)\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"Average Importance\", fontsize=12)\n",
        "plt.title(f\"Top {top_k} Most Important Features\", fontsize=14)\n",
        "\n",
        "# Create a legend for CircRegion\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [Patch(facecolor=color, label=region) for region, color in region_color_map.items()]\n",
        "plt.legend(handles=legend_elements, title=\"Brain Macroregion\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Concatenate all DataFrames along columns\n",
        "concat_df = pd.concat(all_feature_importances_2, axis=1)\n",
        "\n",
        "# Average importance scores across all batches\n",
        "mean_importance = concat_df.mean(axis=1)\n",
        "\n",
        "# Create final DataFrame\n",
        "df_mean_importance = mean_importance.reset_index()\n",
        "df_mean_importance.columns = ['Feature', 'AverageImportance']\n",
        "\n",
        "# Sort descending by importance\n",
        "df_mean_importance = df_mean_importance.sort_values(by='AverageImportance', ascending=False)\n",
        "df_mean_importance.reset_index(drop=True, inplace=True)\n",
        "df_mean_importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_mean_importance['FeatureName'] = df_mean_importance['Feature'].map(feature_name_map)\n",
        "df_mean_importance['CircRegion'] = df_mean_importance['Feature'].map(circ_region_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply a clean style\n",
        "sns.set(style=\"ticks\")\n",
        "\n",
        "# Number of top features\n",
        "top_k = 20\n",
        "\n",
        "# Get top k sorted rows by importance\n",
        "top_df = df_mean_importance.nlargest(top_k, 'AverageImportance').copy()\n",
        "top_df = top_df[::-1]  # Reverse for barh plotting\n",
        "\n",
        "# Define colors by CircRegion using a color palette\n",
        "unique_regions = top_df['CircRegion'].unique()\n",
        "palette = sns.color_palette(\"deep\", len(unique_regions))[::-1]\n",
        "region_color_map = {region: palette[i] for i, region in enumerate(unique_regions)}\n",
        "bar_colors = top_df['CircRegion'].map(region_color_map)\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(6, 5))\n",
        "bars = plt.barh(range(top_k), top_df['AverageImportance'], color=bar_colors)\n",
        "\n",
        "# Y-axis feature labels\n",
        "plt.yticks(range(top_k), top_df['FeatureName'], fontsize=10)\n",
        "\n",
        "# Add text annotations (importance scores)\n",
        "for i, val in enumerate(top_df['AverageImportance']):\n",
        "    plt.text(val + 0.01, i, f'{val:.2f}', va='center', fontsize=9)\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"Average Importance\", fontsize=12)\n",
        "plt.title(f\"Top {top_k} Most Important Features\", fontsize=14)\n",
        "\n",
        "# Create a legend for CircRegion\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [Patch(facecolor=color, label=region) for region, color in region_color_map.items()]\n",
        "plt.legend(handles=legend_elements, title=\"Brain Region\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# List of batch numbers you used\n",
        "ext_test_batches = [1, 3, 4, 5, 6, 7]\n",
        "\n",
        "# Initialize the list to store DataFrames\n",
        "all_node_importances = []\n",
        "\n",
        "# Loop through the batch numbers, read each CSV, set index, and append\n",
        "for batch in ext_test_batches:\n",
        "    filename = f\"node_importance_batch{batch}.csv\"\n",
        "    df = pd.read_csv(filename)\n",
        "    df = df.set_index('Feature')  # Set 'Feature' column as index\n",
        "    all_node_importances.append(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Concatenate all DataFrames along columns\n",
        "concat_df = pd.concat(all_feature_importances, axis=1)\n",
        "\n",
        "# Average importance scores across all batches\n",
        "mean_importance = concat_df.mean(axis=1)\n",
        "\n",
        "# Create final DataFrame\n",
        "df_mean_importance = mean_importance.reset_index()\n",
        "df_mean_importance.columns = ['Feature', 'AverageImportance']\n",
        "\n",
        "# Sort descending by importance\n",
        "df_mean_importance = df_mean_importance.sort_values(by='AverageImportance', ascending=False)\n",
        "df_mean_importance.reset_index(drop=True, inplace=True)\n",
        "df_mean_importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_mean_importance['FeatureName'] = df_mean_importance['Feature'].map(feature_name_map)\n",
        "df_mean_importance['CircRegion'] = df_mean_importance['Feature'].map(circ_region_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "avg_importance = np.mean(np.stack(all_node_importances, axis=2), axis=2)\n",
        "\n",
        "df_node_importance = pd.DataFrame({\n",
        "    \"Feature\": np.arange(avg_importance.shape[0]),\n",
        "    \"AverageImportance\": avg_importance.flatten()\n",
        "})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_node_importance['FeatureName'] = df_node_importance['Feature'].map(feature_name_map)\n",
        "df_node_importance['CircRegion'] = df_node_importance['Feature'].map(circ_region_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_node_importance = df_node_importance.sort_values(by='AverageImportance', ascending=False)\n",
        "df_node_importance.reset_index(drop=True, inplace=True)\n",
        "df_node_importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Apply a clean style\n",
        "sns.set(style=\"ticks\")\n",
        "\n",
        "# Number of top features\n",
        "top_k = 10\n",
        "\n",
        "# Get top k sorted rows by importance\n",
        "top_df = df_node_importance.nlargest(top_k, 'AverageImportance').copy()\n",
        "top_df = top_df[::-1]  # Reverse for barh plotting\n",
        "\n",
        "# Define colors by CircRegion using a color palette\n",
        "unique_regions = top_df['CircRegion'].unique()\n",
        "palette = sns.color_palette(\"deep\", len(unique_regions))[::-1]\n",
        "region_color_map = {region: palette[i] for i, region in enumerate(unique_regions)}\n",
        "bar_colors = top_df['CircRegion'].map(region_color_map)\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(6, 5))\n",
        "bars = plt.barh(range(top_k), top_df['AverageImportance'], color=bar_colors)\n",
        "\n",
        "sns.despine()\n",
        "\n",
        "# Y-axis feature labels\n",
        "plt.yticks(range(top_k), top_df['FeatureName'], fontsize=10)\n",
        "\n",
        "# Add text annotations (importance scores)\n",
        "for i, val in enumerate(top_df['AverageImportance']):\n",
        "    plt.text(val + 0.01, i, f'{val:.2f}', va='center', fontsize=9)\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"Average Importance\", fontsize=12)\n",
        "plt.title(f\"Top {top_k} Most Important Nodes\", fontsize=14)\n",
        "\n",
        "# Create a legend for CircRegion\n",
        "from matplotlib.patches import Patch\n",
        "legend_elements = [Patch(facecolor=color, label=region) for region, color in region_color_map.items()]\n",
        "plt.legend(handles=legend_elements, title=\"Brain Region\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_node_importance = df_node_importance.sort_values(by='Feature', ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(df_node_importance['AverageImportance'].values.reshape(-1, 1), cmap=\"Reds\") \n",
        "# plt.title(\"Node Importance via CAM\")\n",
        "plt.xlabel(\"Importance Score\")\n",
        "plt.ylabel(\"Nodes\")\n",
        "plt.savefig(\"node_importance_cam.png\", dpi = 300)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Ek88DZVppIJU"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
